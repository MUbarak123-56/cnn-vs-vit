# cnn-vs-vit
This is our paper presentation for DS 5899 - Transformers. The topic of discussion: Do Vision Transformers see like Convolution Neural Networks?

[Our Presentation Slides](https://docs.google.com/presentation/d/1NSiqBuMzJEszaGAs3XfNuMyi_4NkqIEVPTo7G4usgJk/edit?usp=sharing)

## Overview

## Paper review

## CNN vs ViT

## Summary

> ViT has created a new pathway for learning from image data via Attention
> 
> ViT differs heavily from CNNs in terms of its ability to recognize object
> 
> - It views images uniformly across all layers
> 
> ViT needs to have been pre-trained on a lot of data before it can go on to clearly outperform CNNs


## References

[Do Vision Transformers See Like Convolution Neural Networks?](https://arxiv.org/abs/2108.08810)

[Vision Transformer for Image Classification](https://www.youtube.com/watch?v=HZ4j_U3FC94)

[A Comprehensive Guide to Convolutional Neural Networks â€” the ELI5 way](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)

[Attention augmented convolutional networks.](https://arxiv.org/abs/1904.09925)

[MLP-Mixer: An all-MLP Architecture for Vision](https://arxiv.org/abs/2105.01601)
